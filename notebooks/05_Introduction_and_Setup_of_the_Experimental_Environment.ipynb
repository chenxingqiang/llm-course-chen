{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fce7de",
   "metadata": {},
   "source": [
    "# Lesson 5: Introduction and Setup of the Experimental Environment\n",
    "\n",
    "## Introduction (1 minute)\n",
    "\n",
    "Welcome to our hands-on session on setting up the experimental environment for our LLM course. In the next 12 minutes, we'll dive into the practical aspects of preparing your workspace. This setup will be crucial for all the exercises and projects we'll be doing throughout the course.\n",
    "\n",
    "## Lesson Objectives\n",
    "\n",
    "By the end of this lesson, you will:\n",
    "1. Understand the components of our course's experimental environment\n",
    "2. Set up and configure the online server environment\n",
    "3. Learn about model storage and invocation techniques\n",
    "4. Troubleshoot common setup issues\n",
    "\n",
    "Let's get our hands dirty!\n",
    "\n",
    "## 1. Introduction to the Experimental Environment (2 minutes)\n",
    "\n",
    "Our cloud-based environment ensures everyone has access to the necessary computational resources. Here's what we're working with:\n",
    "\n",
    "- Ubuntu 20.04 LTS as our operating system\n",
    "- Python 3.8+ for programming\n",
    "- CUDA 11.2 for GPU support\n",
    "- PyTorch 1.9+ and Hugging Face Transformers 4.10+ for LLM work\n",
    "- Jupyter Lab for interactive coding\n",
    "- Git for version control\n",
    "- Docker for containerization\n",
    "\n",
    "Let's visualize our setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment='Course Environment')\n",
    "dot.attr(rankdir='TB', size='8,8')\n",
    "\n",
    "dot.node('A', 'Cloud Server (Ubuntu 20.04)')\n",
    "dot.node('B', 'Python 3.8+')\n",
    "dot.node('C', 'CUDA 11.2')\n",
    "dot.node('D', 'PyTorch 1.9+')\n",
    "dot.node('E', 'Transformers 4.10+')\n",
    "dot.node('F', 'Jupyter Lab')\n",
    "dot.node('G', 'Git')\n",
    "dot.node('H', 'Docker')\n",
    "\n",
    "dot.edge('A', 'B')\n",
    "dot.edge('A', 'C')\n",
    "dot.edge('B', 'D')\n",
    "dot.edge('B', 'E')\n",
    "dot.edge('A', 'F')\n",
    "dot.edge('A', 'G')\n",
    "dot.edge('A', 'H')\n",
    "\n",
    "dot.render('course_environment', format='png', cleanup=True)\n",
    "dot.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4be9c0",
   "metadata": {},
   "source": [
    "[Image Placeholder: Detailed diagram of the Course Environment]\n",
    "\n",
    "## 2. Setup and Configuration of the Online Server Environment (5 minutes)\n",
    "\n",
    "Let's go through the setup process step-by-step:\n",
    "\n",
    "1. Log in to the provided cloud server:\n",
    "   ```\n",
    "   ssh student@course-server.com\n",
    "   ```\n",
    "   Use the password provided in your welcome email.\n",
    "\n",
    "2. Update the system:\n",
    "   ```\n",
    "   sudo apt-get update && sudo apt-get upgrade -y\n",
    "   ```\n",
    "\n",
    "3. Install required system packages:\n",
    "   ```\n",
    "   sudo apt-get install -y build-essential libssl-dev zlib1g-dev \\\n",
    "   libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm \\\n",
    "   libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev \\\n",
    "   liblzma-dev python-openssl git\n",
    "   ```\n",
    "\n",
    "4. Install Miniconda:\n",
    "   ```\n",
    "   wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "   bash Miniconda3-latest-Linux-x86_64.sh\n",
    "   ```\n",
    "   Follow the prompts to install Miniconda.\n",
    "\n",
    "5. Create a new conda environment:\n",
    "   ```\n",
    "   conda create -n llm_env python=3.8 -y\n",
    "   conda activate llm_env\n",
    "   ```\n",
    "\n",
    "6. Install PyTorch with CUDA support:\n",
    "   ```\n",
    "   conda install pytorch torchvision torchaudio cudatoolkit=11.2 -c pytorch\n",
    "   ```\n",
    "\n",
    "7. Install Transformers and other required packages:\n",
    "   ```\n",
    "   pip install transformers datasets scikit-learn matplotlib jupyter\n",
    "   ```\n",
    "\n",
    "8. Clone the course repository:\n",
    "   ```\n",
    "   git clone https://github.com/course/llm-training.git\n",
    "   cd llm-training\n",
    "   ```\n",
    "\n",
    "9. Start Jupyter Lab:\n",
    "   ```\n",
    "   jupyter lab --no-browser --port=8888\n",
    "   ```\n",
    "\n",
    "10. Set up port forwarding on your local machine:\n",
    "    ```\n",
    "    ssh -N -f -L localhost:8888:localhost:8888 student@course-server.com\n",
    "    ```\n",
    "\n",
    "11. Open `http://localhost:8888` in your browser and enter the token provided in the terminal.\n",
    "\n",
    "## 3. Model Storage and Invocation (3 minutes)\n",
    "\n",
    "We'll be working with various pre-trained models throughout the course. Here's how we'll manage and use them:\n",
    "\n",
    "1. Models will be stored in a dedicated `/models` directory on the server.\n",
    "\n",
    "2. We'll use the Hugging Face `transformers` library to load and use models. Here's a quick example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee9d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "model_path = \"/models/\" + model_name\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModel.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, world!\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "print(f\"Input text: {text}\")\n",
    "print(f\"Output shape: {outputs.last_hidden_state.shape}\")\n",
    "print(f\"Device used: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be551938",
   "metadata": {},
   "source": [
    "This code loads a BERT model, moves it to GPU if available, and performs a forward pass with a simple input.\n",
    "\n",
    "3. To download a new model, use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "save_path = f\"/models/{model_name}\"\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdd6adc",
   "metadata": {},
   "source": [
    "## Troubleshooting Common Issues (1 minute)\n",
    "\n",
    "1. If you encounter CUDA out of memory errors, try reducing batch sizes or model sizes.\n",
    "2. For package conflicts, create a new conda environment and install packages one by one.\n",
    "3. If Jupyter Lab doesn't start, check if the port is already in use: `lsof -i :8888`\n",
    "\n",
    "## Additional Resources (1 minute)\n",
    "\n",
    "1. Jupyter Lab Documentation: https://jupyterlab.readthedocs.io/en/stable/\n",
    "2. Conda Cheat Sheet: https://docs.conda.io/projects/conda/en/latest/user-guide/cheatsheet.html\n",
    "3. PyTorch Documentation: https://pytorch.org/docs/stable/index.html\n",
    "4. Hugging Face Transformers Documentation: https://huggingface.co/transformers/\n",
    "5. Git Cheat Sheet: https://education.github.com/git-cheat-sheet-education.pdf\n",
    "6. CUDA Programming Guide: https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html\n",
    "\n",
    "## Conclusion and Next Steps (1 minute)\n",
    "\n",
    "Congratulations! You've now set up a powerful environment for LLM development. Before our next lesson:\n",
    "\n",
    "1. Try loading different models and running inferences\n",
    "2. Experiment with GPU vs. CPU performance\n",
    "3. Familiarize yourself with Jupyter Lab's interface\n",
    "\n",
    "If you encounter any issues, please reach out to our support team at support@llmcourse.com.\n",
    "\n",
    "Next, we'll dive into the fascinating world of tokenization and embeddings. Get ready for some exciting NLP adventures!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
