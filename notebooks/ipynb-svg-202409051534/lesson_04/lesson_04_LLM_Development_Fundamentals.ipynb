{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993a8eb1",
   "metadata": {},
   "source": [
    "# 1.Course Title: Comprehensive LLM Development Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22010686",
   "metadata": {},
   "source": [
    "![Mermaid diagram](lesson_04_mermaid_1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8828421",
   "metadata": {},
   "source": [
    "Advanced Fundamentals of Large Language Model Development\n",
    "\n",
    "# 2. Learning Objectives\n",
    "\n",
    "By the end of this comprehensive lesson, students will be able to:\n",
    "\n",
    "1. Thoroughly understand and explain the LLM development pipeline\n",
    "\n",
    "2. Master key concepts including tokenization, prompting, and fine-tuning\n",
    "\n",
    "3. Implement and apply advanced techniques such as reward modeling and model quantization\n",
    "\n",
    "4. Critically evaluate different approaches in LLM development and their trade-offs\n",
    "\n",
    "5. Design and execute experiments to test LLM performance and behavior\n",
    "\n",
    "6. Understand the ethical implications and challenges in LLM development\n",
    "\n",
    "   \n",
    "\n",
    "# 3. Overview\n",
    "\n",
    "This in-depth lesson covers eight key concepts, providing a comprehensive exploration of LLM development fundamentals:\n",
    "\n",
    "1. Advanced Tokenization Techniques\n",
    "\n",
    "2. Sophisticated Prompting Strategies\n",
    "\n",
    "3. Comprehensive Data Preparation and Preprocessing\n",
    "\n",
    "4. In-depth Pre-training Methodologies\n",
    "\n",
    "5. Advanced Fine-tuning Techniques\n",
    "\n",
    "6. Reward Modeling and Reinforcement Learning in LLMs\n",
    "\n",
    "7. Efficient Model Quantization Strategies\n",
    "\n",
    "8. Accurate Model Performance Estimation and Evaluation\n",
    "\n",
    "   \n",
    "\n",
    "# 4. Detailed Content\n",
    "\n",
    "## 4.1 Concept 1: Advanced Tokenization Techniques\n",
    "\n",
    "### 4.1.1 Explanation\n",
    "\n",
    "Tokenization is the foundational process of converting raw text into a sequence of tokens that the model can process. It's a crucial step that significantly influences the model's ability to understand and generate text. Advanced tokenization techniques go beyond simple word or character splitting, employing sophisticated algorithms to capture semantic and syntactic information [1].\n",
    "\n",
    "Key aspects of advanced tokenization include:\n",
    "\n",
    "- Subword tokenization algorithms (BPE, WordPiece, SentencePiece)\n",
    "- Handling of out-of-vocabulary words\n",
    "- Multilingual tokenization\n",
    "- Special token management (e.g., [CLS], [SEP], [MASK])\n",
    "- Impact of tokenization on model performance and training efficiency\n",
    "\n",
    "### 4.1.2 Case Study: Multilingual Tokenization for Global Language Models\n",
    "\n",
    "Imagine you're developing a language model that needs to handle multiple languages, including those with non-Latin scripts. Your tokenization strategy needs to effectively handle a diverse range of linguistic structures and writing systems.\n",
    "\n",
    "### 4.1.3 Code: Advanced Tokenization Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class AdvancedTokenizationDemo:\n",
    "    def __init__(self, model_names: List[str]):\n",
    "        self.tokenizers = {name: AutoTokenizer.from_pretrained(name) for name in model_names}\n",
    "    \n",
    "    def compare_tokenization(self, text: str):\n",
    "        results = {}\n",
    "        for name, tokenizer in self.tokenizers.items():\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "            token_ids = tokenizer.encode(text)\n",
    "            results[name] = {\n",
    "                'tokens': tokens,\n",
    "                'token_ids': token_ids,\n",
    "                'vocab_size': tokenizer.vocab_size,\n",
    "                'unk_token': tokenizer.unk_token,\n",
    "            }\n",
    "        return results\n",
    "    \n",
    "    def analyze_tokenization(self, text: str):\n",
    "        results = self.compare_tokenization(text)\n",
    "        for name, result in results.items():\n",
    "            print(f\"\\nTokenization with {name}:\")\n",
    "            print(f\"Tokens: {result['tokens']}\")\n",
    "            print(f\"Token IDs: {result['token_ids']}\")\n",
    "            print(f\"Vocabulary Size: {result['vocab_size']}\")\n",
    "            print(f\"Unknown Token: {result['unk_token']}\")\n",
    "    \n",
    "    def visualize_token_lengths(self, text: str):\n",
    "        results = self.compare_tokenization(text)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for name, result in results.items():\n",
    "            plt.hist([len(token) for token in result['tokens']], bins=range(1, 20), alpha=0.5, label=name)\n",
    "        plt.xlabel('Token Length')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of Token Lengths')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def handle_out_of_vocabulary(self, text: str):\n",
    "        results = {}\n",
    "        for name, tokenizer in self.tokenizers.items():\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "            unk_token = tokenizer.unk_token\n",
    "            oov_tokens = [token for token in tokens if token == unk_token]\n",
    "            results[name] = {\n",
    "                'oov_count': len(oov_tokens),\n",
    "                'oov_ratio': len(oov_tokens) / len(tokens)\n",
    "            }\n",
    "        return results\n",
    "\n",
    "# Usage example\n",
    "demo = AdvancedTokenizationDemo(['bert-base-uncased', 'gpt2', 'xlm-roberta-base'])\n",
    "\n",
    "# Compare tokenization across models\n",
    "text = \"The quick brown fox jumps over the lazy dog. 这是一个多语言的例子。\"\n",
    "demo.analyze_tokenization(text)\n",
    "\n",
    "# Visualize token length distribution\n",
    "demo.visualize_token_lengths(text)\n",
    "\n",
    "# Handle out-of-vocabulary words\n",
    "rare_text = \"The supercalifragilisticexpialidocious AI model achieved state-of-the-art results.\"\n",
    "oov_results = demo.handle_out_of_vocabulary(rare_text)\n",
    "for name, result in oov_results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"OOV tokens: {result['oov_count']}\")\n",
    "    print(f\"OOV ratio: {result['oov_ratio']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc62b1",
   "metadata": {},
   "source": [
    "This code demonstrates advanced tokenization techniques, including comparison of different tokenizers, visualization of token length distributions, and handling of out-of-vocabulary words.\n",
    "\n",
    "### 4.1.4 Reflection\n",
    "\n",
    "Advanced tokenization techniques play a crucial role in the performance and capabilities of LLMs. The choice of tokenization strategy can significantly impact a model's ability to handle different languages, rare words, and complex linguistic structures.\n",
    "\n",
    "Consider the following questions:\n",
    "\n",
    "1. How does the choice of tokenization algorithm affect a model's performance on different languages or domains?\n",
    "2. What are the trade-offs between using a large vocabulary with simple tokenization versus a smaller vocabulary with subword tokenization?\n",
    "3. How might tokenization strategies need to evolve to better handle code, mathematical expressions, or other specialized text formats in LLMs?\n",
    "\n",
    "## 4.2 Concept 2: Sophisticated Prompting Strategies\n",
    "\n",
    "### 4.2.1 Explanation\n",
    "\n",
    "Prompting is a powerful technique that allows LLMs to perform a wide range of tasks without additional training. Sophisticated prompting strategies go beyond simple text completion, enabling complex reasoning, task decomposition, and even self-improvement [2].\n",
    "\n",
    "Key aspects of advanced prompting include:\n",
    "\n",
    "- Zero-shot and few-shot learning\n",
    "- Chain-of-thought prompting\n",
    "- Self-consistency and multiple path reasoning\n",
    "- Prompt engineering and optimization\n",
    "- Task decomposition through prompting\n",
    "- Ethical considerations in prompt design\n",
    "\n",
    "### 4.2.2 Case Study: Developing a Complex Reasoning System\n",
    "\n",
    "Imagine you're building a system that needs to perform complex logical reasoning tasks, such as solving multi-step math problems or analyzing legal documents. You need to design prompting strategies that can guide the model through the reasoning process step-by-step.\n",
    "\n",
    "### 4.2.3 Code: Advanced Prompting Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from typing import List, Dict\n",
    "import re\n",
    "\n",
    "class AdvancedPromptingSystem:\n",
    "    def __init__(self, api_key: str):\n",
    "        openai.api_key = api_key\n",
    "    \n",
    "    def generate_response(self, prompt: str, model: str = \"text-davinci-002\", max_tokens: int = 150):\n",
    "        response = openai.Completion.create(\n",
    "            engine=model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    \n",
    "    def chain_of_thought_prompt(self, question: str) -> str:\n",
    "        prompt = f\"\"\"Question: {question}\n",
    "Let's approach this step-by-step:\n",
    "1)\"\"\"\n",
    "        return self.generate_response(prompt, max_tokens=300)\n",
    "    \n",
    "    def self_consistency_prompt(self, question: str, n_attempts: int = 3) -> List[str]:\n",
    "        responses = []\n",
    "        for _ in range(n_attempts):\n",
    "            prompt = f\"Question: {question}\\nLet's think about this carefully and solve it step-by-step:\"\n",
    "            responses.append(self.generate_response(prompt, max_tokens=200))\n",
    "        return responses\n",
    "    \n",
    "    def task_decomposition_prompt(self, task: str) -> Dict[str, str]:\n",
    "        decomposition_prompt = f\"\"\"Task: {task}\n",
    "To accomplish this task, let's break it down into smaller subtasks:\n",
    "1)\"\"\"\n",
    "        decomposition = self.generate_response(decomposition_prompt, max_tokens=200)\n",
    "        subtasks = re.findall(r'\\d+\\)(.*?)(?=\\d+\\)|$)', decomposition, re.DOTALL)\n",
    "        return {f\"Subtask {i+1}\": subtask.strip() for i, subtask in enumerate(subtasks)}\n",
    "    \n",
    "    def ethical_consideration_prompt(self, scenario: str) -> str:\n",
    "        prompt = f\"\"\"Scenario: {scenario}\n",
    "Let's carefully consider the ethical implications of this scenario:\n",
    "1) Potential benefits:\n",
    "2) Potential risks or harms:\n",
    "3) Ethical principles involved:\n",
    "4) Possible alternatives or mitigations:\n",
    "5) Conclusion and recommendations:\n",
    "\"\"\"\n",
    "        return self.generate_response(prompt, max_tokens=300)\n",
    "\n",
    "# Usage example\n",
    "prompt_system = AdvancedPromptingSystem(\"your-api-key-here\")\n",
    "\n",
    "# Chain-of-thought prompting\n",
    "math_question = \"If a train travels 120 km in 2 hours, what is its average speed in meters per second?\"\n",
    "cot_response = prompt_system.chain_of_thought_prompt(math_question)\n",
    "print(\"Chain of Thought Response:\")\n",
    "print(cot_response)\n",
    "\n",
    "# Self-consistency prompting\n",
    "consistency_responses = prompt_system.self_consistency_prompt(math_question)\n",
    "print(\"\\nSelf-Consistency Responses:\")\n",
    "for i, response in enumerate(consistency_responses, 1):\n",
    "    print(f\"\\nAttempt {i}:\")\n",
    "    print(response)\n",
    "\n",
    "# Task decomposition\n",
    "complex_task = \"Develop a marketing strategy for a new eco-friendly product launch\"\n",
    "subtasks = prompt_system.task_decomposition_prompt(complex_task)\n",
    "print(\"\\nTask Decomposition:\")\n",
    "for subtask, description in subtasks.items():\n",
    "    print(f\"\\n{subtask}:\")\n",
    "    print(description)\n",
    "\n",
    "# Ethical consideration\n",
    "ethical_scenario = \"A company is developing an AI system that can predict criminal behavior based on social media activity\"\n",
    "ethical_analysis = prompt_system.ethical_consideration_prompt(ethical_scenario)\n",
    "print(\"\\nEthical Analysis:\")\n",
    "print(ethical_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4a65a",
   "metadata": {},
   "source": [
    "This code demonstrates advanced prompting techniques including chain-of-thought reasoning, self-consistency through multiple attempts, task decomposition, and ethical consideration prompts.\n",
    "\n",
    "### 4.2.4 Reflection\n",
    "\n",
    "Sophisticated prompting strategies can dramatically enhance the capabilities of LLMs, allowing them to perform complex reasoning tasks and handle a wide range of applications. However, they also raise important questions about the true understanding and capabilities of these models.\n",
    "\n",
    "Consider the following questions:\n",
    "\n",
    "1. How do different prompting strategies affect the reliability and consistency of LLM outputs?\n",
    "2. What are the limitations of current prompting techniques, and how might they be overcome?\n",
    "3. How can we ensure that prompting strategies are ethically sound and don't inadvertently introduce biases or misinformation?\n",
    "\n",
    "## 4.3 Concept 3: Comprehensive Data Preparation and Preprocessing\n",
    "\n",
    "### 4.3.1 Explanation\n",
    "\n",
    "Data preparation and preprocessing are critical steps in LLM development that can significantly impact model performance. Comprehensive approaches go beyond basic cleaning to include advanced techniques for data augmentation, bias mitigation, and quality assurance [3].\n",
    "\n",
    "Key aspects of advanced data preparation include:\n",
    "\n",
    "- Data collection and curation strategies\n",
    "- Advanced text cleaning and normalization techniques\n",
    "- Data augmentation methods for LLMs\n",
    "- Handling of multilingual and code-mixed data\n",
    "- Bias detection and mitigation in training data\n",
    "- Privacy-preserving data preprocessing\n",
    "- Quality assurance and validation techniques\n",
    "\n",
    "### 4.3.2 Case Study: Preparing a Diverse and Unbiased Dataset for a Multilingual LLM\n",
    "\n",
    "Imagine you're tasked with preparing a dataset for training a large multilingual language model that will be used in various applications across different cultures and domains. You need to ensure the dataset is diverse, representative, and free from harmful biases.\n",
    "\n",
    "### 4.3.3 Code: Advanced Data Preparation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb1314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Dict\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "class AdvancedDataPreparation:\n",
    "    def __init__(self):\n",
    "        nltk.download('wordnet')\n",
    "        self.translation_model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-ROMANCE\")\n",
    "        self.translation_tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ROMANCE\")\n",
    "    \n",
    "    def load_and_split_data(self, file_path: str, test_size: float = 0.2):\n",
    "        df = pd.read_csv(file_path)\n",
    "        train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)\n",
    "        return train_df, test_df\n",
    "    \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def augment_data(self, text: str, n_augmentations: int = 1) -> List[str]:\n",
    "        augmented_texts = [text]\n",
    "        words = text.split()\n",
    "        for _ in range(n_augmentations):\n",
    "            new_text = []\n",
    "            for word in words:\n",
    "                synonyms = wordnet.synsets(word)\n",
    "                if synonyms:\n",
    "                    new_word = synonyms[0].lemmas()[0].name()\n",
    "                    new_text.append(new_word)\n",
    "                else:\n",
    "                    new_text.append(word)\n",
    "            augmented_texts.append(\" \".join(new_text))\n",
    "        return augmented_texts\n",
    "    \n",
    "    def translate_text(self, text: str, target_lang: str) -> str:\n",
    "        inputs = self.translation_tokenizer(text, return_tensors=\"pt\")\n",
    "        translated = self.translation_model.generate(**inputs)\n",
    "        return self.translation_tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    \n",
    "    def detect_bias(self, texts: List[str], sensitive_terms: Dict[str, List[str]]) -> Dict[str, float]:\n",
    "        bias_scores = {category: 0 for category in sensitive_terms}\n",
    "        for text in texts:\n",
    "            for category, terms in sensitive_terms.items():\n",
    "                for term in terms:\n",
    "                    if term in text.lower():\n",
    "                        bias_scores[category] += 1\n",
    "        for category in bias_scores:\n",
    "            bias_scores[category] /= len(texts)for category in bias_scores:\n",
    "            bias_scores[category] /= len(texts)\n",
    "        return bias_scores\n",
    "    \n",
    "    def prepare_data(self, file_path: str, augment: bool = True, translate: bool = True):\n",
    "        train_df, test_df = self.load_and_split_data(file_path)\n",
    "        \n",
    "        # Clean and preprocess\n",
    "        train_df['cleaned_text'] = train_df['text'].apply(self.clean_text)\n",
    "        test_df['cleaned_text'] = test_df['text'].apply(self.clean_text)\n",
    "        \n",
    "        # Augment data\n",
    "        if augment:\n",
    "            train_df['augmented_text'] = train_df['cleaned_text'].apply(lambda x: self.augment_data(x, n_augmentations=2))\n",
    "            train_df = train_df.explode('augmented_text').reset_index(drop=True)\n",
    "        \n",
    "        # Translate data\n",
    "        if translate:\n",
    "            train_df['translated_text'] = train_df['cleaned_text'].apply(lambda x: self.translate_text(x, target_lang='fr'))\n",
    "        \n",
    "        # Detect bias\n",
    "        sensitive_terms = {\n",
    "            'gender': ['he', 'she', 'man', 'woman'],\n",
    "            'race': ['black', 'white', 'asian', 'hispanic'],\n",
    "            'religion': ['christian', 'muslim', 'jewish', 'hindu']\n",
    "        }\n",
    "        bias_scores = self.detect_bias(train_df['cleaned_text'].tolist(), sensitive_terms)\n",
    "        \n",
    "        return train_df, test_df, bias_scores\n",
    "\n",
    "# Usage example\n",
    "data_prep = AdvancedDataPreparation()\n",
    "train_data, test_data, bias_scores = data_prep.prepare_data('path_to_your_data.csv')\n",
    "\n",
    "print(\"Training Data Shape:\", train_data.shape)\n",
    "print(\"Test Data Shape:\", test_data.shape)\n",
    "print(\"\\nBias Scores:\")\n",
    "for category, score in bias_scores.items():\n",
    "    print(f\"{category}: {score:.2%}\")\n",
    "\n",
    "# Display sample of prepared data\n",
    "print(\"\\nSample of Prepared Data:\")\n",
    "print(train_data[['cleaned_text', 'augmented_text', 'translated_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9c390",
   "metadata": {},
   "source": [
    "This code demonstrates advanced data preparation techniques including text cleaning, data augmentation, translation for multilingual support, and bias detection.\n",
    "\n",
    "### 4.3.4 Reflection\n",
    "\n",
    "Comprehensive data preparation and preprocessing are crucial for developing high-quality LLMs. These techniques can significantly impact the model's performance, fairness, and generalization capabilities.\n",
    "\n",
    "Consider the following questions:\n",
    "\n",
    "1. How do different data preparation techniques affect the final performance and behavior of LLMs?\n",
    "2. What are the challenges in creating truly representative and unbiased datasets for large-scale language models?\n",
    "3. How can we balance the need for data quantity with the importance of data quality in LLM training?\n",
    "\n",
    "## 4.4 Concept 4: In-depth Pre-training Methodologies\n",
    "\n",
    "### 4.4.1 Explanation\n",
    "\n",
    "Pre-training is a fundamental step in LLM development where the model learns general language understanding from a large corpus of text. Advanced pre-training methodologies go beyond simple language modeling to incorporate structured knowledge, multi-task learning, and efficient training techniques [4].\n",
    "\n",
    "Key aspects of advanced pre-training include:\n",
    "\n",
    "- Masked language modeling and its variants\n",
    "- Contrastive learning in pre-training\n",
    "- Incorporating structured knowledge (e.g., knowledge graphs)\n",
    "- Curriculum learning for efficient pre-training\n",
    "- Multi-task and multi-modal pre-training\n",
    "- Efficient pre-training techniques (e.g., sparse attention, gradient checkpointing)\n",
    "- Continual pre-training and domain adaptation\n",
    "\n",
    "### 4.4.2 Case Study: Pre-training a Domain-Specific LLM for Scientific Literature\n",
    "\n",
    "Imagine you're developing an LLM specifically for understanding and generating scientific literature across multiple disciplines. You need to design a pre-training methodology that effectively captures scientific knowledge and writing styles.\n",
    "\n",
    "### 4.4.3 Code: Advanced Pre-training Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c2aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import random\n",
    "\n",
    "class ScientificTextDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], tokenizer: AutoTokenizer, max_length: int = 512):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, max_length=self.max_length, padding='max_length')\n",
    "        return {key: torch.tensor(val) for key, val in encoding.items()}\n",
    "\n",
    "class AdvancedPreTraining:\n",
    "    def __init__(self, model_name: str = \"bert-base-uncased\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "        self.data_collator = DataCollatorForLanguageModeling(tokenizer=self.tokenizer, mlm=True, mlm_probability=0.15)\n",
    "    \n",
    "    def prepare_dataset(self, texts: List[str]) -> ScientificTextDataset:\n",
    "        return ScientificTextDataset(texts, self.tokenizer)\n",
    "    \n",
    "    def train(self, train_dataset: ScientificTextDataset, output_dir: str, num_train_epochs: int = 3):\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            per_device_train_batch_size=8,\n",
    "            save_steps=10_000,\n",
    "            save_total_limit=2,\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            data_collator=self.data_collator,\n",
    "            train_dataset=train_dataset,\n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        trainer.save_model()\n",
    "    \n",
    "    def curriculum_learning(self, texts: List[str], difficulty_fn, num_epochs: int = 3):\n",
    "        # Sort texts by difficulty\n",
    "        texts_with_difficulty = [(text, difficulty_fn(text)) for text in texts]\n",
    "        texts_with_difficulty.sort(key=lambda x: x[1])\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Calculate curriculum cutoff\n",
    "            cutoff = int(len(texts_with_difficulty) * (epoch + 1) / num_epochs)\n",
    "            epoch_texts = [text for text, _ in texts_with_difficulty[:cutoff]]\n",
    "            \n",
    "            # Prepare dataset and train for one epoch\n",
    "            dataset = self.prepare_dataset(epoch_texts)\n",
    "            self.train(dataset, f\"output_dir_epoch_{epoch}\", num_train_epochs=1)\n",
    "    \n",
    "    def contrastive_pretraining(self, texts: List[str], num_epochs: int = 3):\n",
    "        def create_positive_pair(text):\n",
    "            words = text.split()\n",
    "            if len(words) > 10:\n",
    "                split = random.randint(5, len(words) - 5)\n",
    "                return \" \".join(words[:split]), \" \".join(words[split:])\n",
    "            return text, text\n",
    "        \n",
    "        contrastive_texts = []\n",
    "        for text in texts:\n",
    "            pos1, pos2 = create_positive_pair(text)\n",
    "            contrastive_texts.extend([pos1, pos2])\n",
    "        \n",
    "        dataset = self.prepare_dataset(contrastive_texts)\n",
    "        self.train(dataset, \"output_dir_contrastive\", num_train_epochs=num_epochs)\n",
    "\n",
    "# Usage example\n",
    "pre_trainer = AdvancedPreTraining()\n",
    "\n",
    "# Load your scientific texts\n",
    "df = pd.read_csv('path_to_your_scientific_texts.csv')\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "# Basic pre-training\n",
    "basic_dataset = pre_trainer.prepare_dataset(texts)\n",
    "pre_trainer.train(basic_dataset, \"output_basic_pretrain\")\n",
    "\n",
    "# Curriculum learning\n",
    "def text_difficulty(text):\n",
    "    # This is a simple example; you might use more sophisticated metrics\n",
    "    return len(text.split())\n",
    "\n",
    "pre_trainer.curriculum_learning(texts, text_difficulty)\n",
    "\n",
    "# Contrastive pre-training\n",
    "pre_trainer.contrastive_pretraining(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcceb0f",
   "metadata": {},
   "source": [
    "This code demonstrates advanced pre-training techniques including curriculum learning and contrastive pre-training, which can be particularly effective for domain-specific language models.\n",
    "\n",
    "### 4.4.4 Reflection\n",
    "\n",
    "Advanced pre-training methodologies can significantly enhance the capabilities and efficiency of LLMs. These techniques allow models to capture more nuanced language understanding and domain-specific knowledge.\n",
    "\n",
    "Consider the following questions:\n",
    "\n",
    "1. How do different pre-training objectives affect the downstream performance of LLMs on various tasks?\n",
    "2. What are the trade-offs between general language understanding and domain-specific knowledge in pre-training?\n",
    "3. How can we incorporate structured knowledge (e.g., scientific concepts and relationships) into the pre-training process?\n",
    "\n",
    "## 4.5 Concept 5: Advanced Fine-tuning Techniques\n",
    "\n",
    "### 4.5.1 Explanation\n",
    "\n",
    "Fine-tuning adapts a pre-trained model to specific tasks or domains. Advanced fine-tuning techniques go beyond simple supervised learning to include methods that efficiently adapt large models with limited data and computational resources [5].\n",
    "\n",
    "Key aspects of advanced fine-tuning include:\n",
    "\n",
    "- Parameter-efficient fine-tuning (e.g., adapters, LoRA)\n",
    "- Few-shot and zero-shot fine-tuning\n",
    "- Multi-task fine-tuning\n",
    "- Continual fine-tuning and catastrophic forgetting prevention\n",
    "- Domain adaptation techniques\n",
    "- Fine-tuning with noisy labels and weak supervision\n",
    "- Ethical considerations in fine-tuning\n",
    "\n",
    "### 4.5.2 Case Study: Adapting a Large Language Model for Specialized Medical Tasks\n",
    "\n",
    "Imagine you're working on adapting a large, general-purpose language model for a series of specialized medical tasks, including diagnosis assistance and medical literature summarization. You have limited labeled data and computational resources.\n",
    "\n",
    "### 4.5.3 Code: Advanced Fine-tuning Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cccf9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "\n",
    "class MedicalDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer: AutoTokenizer, max_length: int = 512):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class AdvancedFineTuning:\n",
    "    def __init__(self, model_name: str = \"bert-base-uncased\", num_labels: int = 2):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    def prepare_data(self, texts: List[str], labels: List[int]):\n",
    "        train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n",
    "        train_dataset = MedicalDataset(train_texts, train_labels, self.tokenizer)\n",
    "        val_dataset = MedicalDataset(val_texts, val_labels, self.tokenizer)\n",
    "        return train_dataset, val_dataset\n",
    "    \n",
    "    def train(self, train_dataset, val_dataset, num_epochs: int = 3, batch_size: int = 8):\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        \n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.model.to(device)\n",
    "        \n",
    "        optimizer = AdamW(self.model.parameters(), lr=2e-5)\n",
    "        total_steps = len(train_loader) * num_epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            val_loss = 0\n",
    "            correct_predictions = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['labels'].to(device)\n",
    "                    outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                    val_loss += outputs.loss.item()\n",
    "                    preds = torch.argmax(outputs.logits, dim=1)\n",
    "                    correct_predictions += torch.sum(preds == labels)\n",
    "            \n",
    "            val_accuracy = correct_predictions.double() / len(val_dataset)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    def few_shot_fine_tune(self, texts: List[str], labels: List[int], n_shots: int = 5):\n",
    "        # Select n examples per class\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        few_shot_data = df.groupby('label').apply(lambda x: x.sample(n=n_shots)).reset_index(drop=True)\n",
    "        \n",
    "        train_dataset, val_dataset = self.prepare_data(few_shot_data['text'].tolist(), few_shot_data['label'].tolist())\n",
    "        self.train(train_dataset, val_dataset, num_epochs=10)  # More epochs for few-shot learning\n",
    "    \n",
    "    def continual_fine_tune(self, datasets: List[Dict[str, List]], ewc_lambda: float = 0.1):\n",
    "        # Elastic Weight Consolidation (EWC) for continual learning\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        fisher_dict = {}\n",
    "        optpar_dict = {}\n",
    "        \n",
    "        for task_id, dataset in enumerate(datasets):\n",
    "            train_dataset, val_dataset = self.prepare_data(dataset['texts'], dataset['labels'])\n",
    "            \n",
    "            # Regular fine-tuning\n",
    "            self.train(train_dataset, val_dataset)\n",
    "            \n",
    "            # Compute Fisher Information\n",
    "            self.model.eval()\n",
    "            for batch in DataLoader(train_dataset, batch_size=1, shuffle=True):\n",
    "                self.model.zero_grad()\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                outputs = self.model(input_outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "                \n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        if task_id == 0:\n",
    "                            fisher_dict[name] = param.grad.data.clone().pow(2)\n",
    "                        else:\n",
    "                            fisher_dict[name] += param.grad.data.clone().pow(2)\n",
    "                \n",
    "                if len(fisher_dict) == len(list(self.model.parameters())):\n",
    "                    break\n",
    "            \n",
    "            # Store optimal parameters\n",
    "            optpar_dict = {}\n",
    "            for name, param in self.model.named_parameters():\n",
    "                optpar_dict[name] = param.data.clone()\n",
    "            \n",
    "            # Apply EWC penalty\n",
    "            for name, param in self.model.named_parameters():\n",
    "                fisher_dict[name] /= len(train_dataset)\n",
    "                param.data.add_(ewc_lambda * fisher_dict[name] * (optpar_dict[name] - param.data))\n",
    "\n",
    "# Usage example\n",
    "fine_tuner = AdvancedFineTuning(model_name=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\", num_labels=3)\n",
    "\n",
    "# Prepare your medical datasets\n",
    "diagnosis_data = pd.read_csv('path_to_diagnosis_data.csv')\n",
    "summarization_data = pd.read_csv('path_to_summarization_data.csv')\n",
    "drug_interaction_data = pd.read_csv('path_to_drug_interaction_data.csv')\n",
    "\n",
    "# Few-shot fine-tuning for diagnosis\n",
    "fine_tuner.few_shot_fine_tune(diagnosis_data['text'].tolist(), diagnosis_data['label'].tolist(), n_shots=10)\n",
    "\n",
    "# Continual fine-tuning for multiple tasks\n",
    "datasets = [\n",
    "    {'texts': summarization_data['text'].tolist(), 'labels': summarization_data['label'].tolist()},\n",
    "    {'texts': drug_interaction_data['text'].tolist(), 'labels': drug_interaction_data['label'].tolist()}\n",
    "]\n",
    "fine_tuner.continual_fine_tune(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30d601",
   "metadata": {},
   "source": [
    "This code demonstrates advanced fine-tuning techniques including few-shot learning and continual fine-tuning with Elastic Weight Consolidation (EWC) to prevent catastrophic forgetting.\n",
    "\n",
    "### 4.5.4 Reflection\n",
    "\n",
    "Advanced fine-tuning techniques enable more efficient and effective adaptation of large language models to specific tasks and domains. These methods are particularly crucial when working with limited data or computational resources.\n",
    "\n",
    "Consider the following questions:\n",
    "\n",
    "1. How do parameter-efficient fine-tuning methods compare to full fine-tuning in terms of performance and computational efficiency?\n",
    "2. What are the challenges in adapting a large language model to multiple specialized tasks while maintaining its general language understanding?\n",
    "3. How can we evaluate the effectiveness of fine-tuning when working with limited labeled data in specialized domains?\n",
    "\n",
    "## 4.6 Concept 6: Reward Modeling and Reinforcement Learning in LLMs\n",
    "\n",
    "### 4.6.1 Explanation\n",
    "\n",
    "Reward modeling and reinforcement learning (RL) techniques allow LLMs to learn from human feedback and optimize for specific objectives beyond simple language modeling. These approaches can lead to models that better align with human preferences and values [6].\n",
    "\n",
    "Key aspects include:\n",
    "\n",
    "- Human preference learning\n",
    "- Inverse reinforcement learning for language models\n",
    "- Policy optimization techniques (e.g., PPO) for language generation\n",
    "- Multi-objective reward modeling\n",
    "- Safe exploration in language model RL\n",
    "- Ethical considerations in reward design\n",
    "\n",
    "### 4.6.2 Case Study: Developing an AI Writing Assistant with Human Feedback\n",
    "\n",
    "Imagine you're creating an AI writing assistant that needs to generate high-quality, engaging content while adhering to specific style guidelines and factual accuracy. You want to incorporate human feedback to continuously improve the model's outputs.\n",
    "\n",
    "### 4.6.3 Code: Reward Modeling and RL for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5326f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "class FeedbackDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], scores: List[float], tokenizer: GPT2Tokenizer, max_length: int = 512):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
    "        self.scores = torch.tensor(scores, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['scores'] = self.scores[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scores)\n",
    "\n",
    "class RewardModel(torch.nn.Module):\n",
    "    def __init__(self, model_name: str = \"gpt2\"):\n",
    "        super().__init__()\n",
    "        self.gpt2 = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "        self.score = torch.nn.Linear(self.gpt2.config.n_embd, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        gpt2_output = self.gpt2(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        last_hidden_state = gpt2_output.hidden_states[-1]\n",
    "        return self.score(last_hidden_state[:, -1, :]).squeeze(-1)\n",
    "\n",
    "class LLMWithRL:\n",
    "    def __init__(self, model_name: str = \"gpt2\"):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name).to(self.device)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        self.reward_model = RewardModel(model_name).to(self.device)\n",
    "\n",
    "    def train_reward_model(self, texts: List[str], scores: List[float], num_epochs: int = 3, batch_size: int = 8):\n",
    "        dataset = FeedbackDataset(texts, scores, self.tokenizer)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        optimizer = AdamW(self.reward_model.parameters(), lr=5e-5)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.reward_model.train()\n",
    "            total_loss = 0\n",
    "            for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                scores = batch['scores'].to(self.device)\n",
    "                \n",
    "                predicted_scores = self.reward_model(input_ids, attention_mask)\n",
    "                loss = torch.nn.functional.mse_loss(predicted_scores, scores)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "    def generate_with_rl(self, prompt: str, max_length: int = 50, num_iterations: int = 100):\n",
    "        self.model.eval()\n",
    "        self.reward_model.eval()\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors='pt').to(self.device)\n",
    "        \n",
    "        for _ in range(num_iterations):\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(input_ids, max_length=max_length, num_return_sequences=2, \n",
    "                                              do_sample=True, top_k=50, top_p=0.95)\n",
    "                \n",
    "                rewards = []\n",
    "                for output in outputs:\n",
    "                    reward = self.reward_model(output.unsqueeze(0), attention_mask=torch.ones_like(output.unsqueeze(0)))\n",
    "                    rewards.append(reward.item())\n",
    "                \n",
    "                best_output = outputs[np.argmax(rewards)]\n",
    "                \n",
    "            # Fine-tune the model on the best output\n",
    "            optimizer = AdamW(self.model.parameters(), lr=1e-5)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = self.model(best_output.unsqueeze(0), labels=best_output.unsqueeze(0)).loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        return self.tokenizer.decode(best_output, skip_special_tokens=True)\n",
    "\n",
    "# Usage example\n",
    "llm_rl = LLMWithRL()\n",
    "\n",
    "# Train reward model\n",
    "feedback_texts = [\"This is a great article.\", \"This article needs improvement.\", \"Excellent writing!\"]\n",
    "feedback_scores = [0.9, 0.3, 1.0]\n",
    "llm_rl.train_reward_model(feedback_texts, feedback_scores)\n",
    "\n",
    "# Generate text with RL\n",
    "prompt = \"Write an engaging introduction about artificial intelligence:\"\n",
    "generated_text = llm_rl.generate_with_rl(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee8b9c",
   "metadata": {},
   "source": [
    "This code demonstrates the implementation of a reward model and its integration with a language model using reinforcement learning techniques. The reward model is trained on human feedback, and the language model is then optimized to maximize the predicted reward.\n",
    "\n",
    "### 4.6.4 Reflection\n",
    "\n",
    "Reward modeling and reinforcement learning offer powerful tools for aligning language models with human preferences and specific objectives. However, they also introduce new challenges and ethical considerations.\n",
    "\n",
    "Consider the following questions:\n",
    "\n",
    "1. How can we ensure that reward models accurately capture the nuances of human preferences, especially for subjective tasks like writing?\n",
    "2. What are the potential risks of using reinforcement learning to optimize language models, and how can we mitigate these risks?\n",
    "3. How might reward modeling and RL techniques be combined with other approaches (e.g., few-shot learning, fine-tuning) for more effective LLM development?\n",
    "\n",
    "## 4.7 Concept 7: Efficient Model Quantization Strategies\n",
    "\n",
    "### 4.7.1 Explanation\n",
    "\n",
    "Model quantization is a technique used to reduce the size and computational requirements of large language models while maintaining their performance. Advanced quantization strategies go beyond simple precision reduction to include methods like mixed-precision quantization and quantization-aware training [7].\n",
    "\n",
    "Key aspects include:\n",
    "\n",
    "- Post-training quantization techniques\n",
    "- Quantization-aware training\n",
    "- Mixed-precision quantization\n",
    "- Vector quantization for language models\n",
    "- Hardware-aware quantization\n",
    "- Impact of quantization on model performance and behavior\n",
    "\n",
    "### 4.7.2 Case Study: Deploying a Large Language Model on Edge Devices\n",
    "\n",
    "Imagine you need to deploy a large language model for real-time translation on mobile devices with limited computational resources. You need to significantly reduce the model size and inference time without substantially degrading performance.\n",
    "\n",
    "### 4.7.3 Code: Advanced Model Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd77ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.quantization import quantize_dynamic, quantize_static, prepare, convert\n",
    "import numpy as np\n",
    "\n",
    "class AdvancedModelQuantization:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def dynamic_quantization(self):\n",
    "        quantized_model = quantize_dynamic(\n",
    "            self.model,\n",
    "            {torch.nn.Linear},\n",
    "            dtype=torch.qint8\n",
    "        )\n",
    "        return quantized_model\n",
    "\n",
    "    def static_quantization(self, calibration_data):\n",
    "        model = self.model.eval()\n",
    "\n",
    "        # Define quantization configuration\n",
    "        model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "        # Prepare model for static quantization\n",
    "        model_prepared = prepare(model)\n",
    "\n",
    "        # Calibrate with sample data\n",
    "        with torch.no_grad():\n",
    "            for data in calibration_data:\n",
    "                model_prepared(data)\n",
    "\n",
    "        # Convert to quantized model\n",
    "        quantized_model = convert(model_prepared)\n",
    "\n",
    "        return quantized_model\n",
    "\n",
    "    def mixed_precision_quantization(self):\n",
    "        # This is a simplified example. In practice, you'd use more sophisticated methods.\n",
    "        def quantize_layer(layer):\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                layer.weight.data = layer.weight.data.to(torch.float16)\n",
    "            return layer\n",
    "\n",
    "        mixed_precision_model = self.model.apply(quantize_layer)\n",
    "        return mixed_precision_model\n",
    "\n",
    "    def evaluate_model(self, model, test_data):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_data:\n",
    "                outputs = model(**inputs)\n",
    "                _, predicted = torch.max(outputs.logits, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        return correct / total\n",
    "\n",
    "    def compare_models(self, test_data):\n",
    "        original_accuracy = self.evaluate_model(self.model, test_data)\n",
    "        \n",
    "        dynamic_quantized = self.dynamic_quantization()\n",
    "        dynamic_accuracy = self.evaluate_model(dynamic_quantized, test_data)\n",
    "        \n",
    "        static_quantized = self.static_quantization(test_data[:100])  # Use first 100 samples for calibration\n",
    "        static_accuracy = self.evaluate_model(static_quantized, test_data)\n",
    "        \n",
    "        mixed_precision = self.mixed_precision_quantization()\n",
    "        mixed_precision_accuracy = self.evaluate_model(mixed_precision, test_data)\n",
    "        \n",
    "        print(f\"Original Model Accuracy: {original_accuracy:.4f}\")\n",
    "        print(f\"Dynamic Quantized Model Accuracy: {dynamic_accuracy:.4f}\")\n",
    "        print(f\"Static Quantized Model Accuracy: {static_accuracy:.4f}\")\n",
    "        print(f\"Mixed Precision Model Accuracy: {mixed_precision_accuracy:.4f}\")\n",
    "        \n",
    "        original_size = sum(p.numel() for p in self.model.parameters()) * 4 / 1e6  # Size in MB\n",
    "        quantized_size = sum(p.numel() for p in dynamic_quantized.parameters()) / 1e6  # Size in MB\n",
    "        \n",
    "        print(f\"Original Model Size: {original_size:.2f} MB\")\n",
    "        print(f\"Quantized Model Size: {quantized_size:.2f} MB\")\n",
    "        print(f\"Size Reduction: {(1 - quantized_size/original_size)*100:.2f}%\")\n",
    "\n",
    "# Usage example\n",
    "quantizer = AdvancedModelQuantization(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Prepare some test data\n",
    "test_texts = [\"This movie is great!\", \"I didn't like the book.\", \"The restaurant was okay.\"]\n",
    "test_labels = torch.tensor([1, 0, 1])  # 1 for positive, 0 for negative\n",
    "inputs = quantizer.tokenizer(test_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "test_data = [(inputs, test_labels)]\n",
    "\n",
    "quantizer.compare_models(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758b9c3",
   "metadata": {},
   "source": [
    "This code demonstrates various quantization techniques including dynamic quantization, static quantization, and a simplified mixed-precision quantization. It also compares the performance and size of the quantized models with the original model.\n",
    "\n",
    "### 4.7.4 Reflection\n",
    "\n",
    "Efficient model quantization is crucial for deploying large language models in resource-constrained environments. However, it requires careful consideration of the trade-offs between model size, inference speed, and performance.\n",
    "\n",
    "Consider the following questions:\n",
    "\n",
    "1. How do different quantization strategies affect the performance of language models on various tasks?\n",
    "2. What are the challenges in quantizing large language models while maintaining their complex language understanding capabilities?\n",
    "3. How might hardware-specific quantization techniques be developed to optimize LLM performance on different devices?\n",
    "\n",
    "## 4.8 Concept 8: Accurate Model Performance Estimation and Evaluation\n",
    "\n",
    "### 4.8.1 Explanation\n",
    "\n",
    "Accurate performance estimation and evaluation are crucial for understanding the capabilities and limitations of large language models. This involves not only traditional metrics but also more sophisticated evaluation techniques that can capture the nuanced performance of LLMs across various tasks and domains [8].\n",
    "\n",
    "Key aspects include:\n",
    "\n",
    "- Comprehensive evaluation frameworks for LLMs\n",
    "- Task-specific and general-purpose evaluation metrics\n",
    "- Robustness and fairness evaluation\n",
    "- Evaluation of model calibration and uncertainty\n",
    "- Human evaluation and alignment assessment\n",
    "- Evaluation of safety and ethical considerations\n",
    "\n",
    "### 4.8.2 Case Study: Evaluating a Multilingual, Multi-task Language Model\n",
    "\n",
    "Imagine you've developed a large language model capable of performing various tasks (e.g., translation, summarization, question-answering) across multiple languages. You need to design a comprehensive evaluation strategy that accurately assesses its performance across these diverse capabilities.\n",
    "\n",
    "### 4.8.3 Code: Advanced Model Evaluation Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae021bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class AdvancedModelEvaluation:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def evaluate_classification(self, dataset_name: str, text_column: str, label_column: str):\n",
    "        dataset = load_dataset(dataset_name, split='test')\n",
    "        texts = dataset[text_column]\n",
    "        labels = dataset[label_column]\n",
    "        \n",
    "        predictions = []\n",
    "        for text in texts:\n",
    "            inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "                predictions.append(pred)\n",
    "        \n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "        conf_matrix = confusion_matrix(labels, predictions)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'confusion_matrix': conf_matrix\n",
    "        }\n",
    "\n",
    "    def evaluate_generation(self, prompts: List[str], reference_outputs: List[str]):\n",
    "        generator = pipeline('text-generation', model=self.model, tokenizer=self.tokenizer, device=0)\n",
    "        generated_outputs = generator(prompts, max_length=100, num_return_sequences=1)\n",
    "        generated_texts = [output[0]['generated_text'] for output in generated_outputs]\n",
    "        \n",
    "        # Here you might use more sophisticated metrics like BLEU, ROUGE, or BERTScore\n",
    "        # For simplicity, we'll use a basic string matching\n",
    "        matches = sum(gen.strip() == ref.strip() for gen, ref in zip(generated_texts, reference_outputs))\n",
    "        accuracy = matches / len(prompts)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'generated_texts': generated_texts\n",
    "        }\n",
    "\n",
    "    def evaluate_robustness(self, texts: List[str], labels: List[int], perturbation_func):\n",
    "        original_acc = self.evaluate_texts(texts, labels)['accuracy']\n",
    "        perturbed_texts = [perturbation_func(text) for text in texts]\n",
    "        perturbed_acc = self.evaluate_texts(perturbed_texts, labels)['accuracy']\n",
    "        \n",
    "        return {\n",
    "            'original_accuracy': original_acc,\n",
    "            'perturbed_accuracy': perturbed_acc,\n",
    "            'robustness_score': perturbed_acc / original_acc\n",
    "        }\n",
    "\n",
    "    def evaluate_fairness(self, texts: List[str], labels: List[int], sensitive_attribute: List[str]):\n",
    "        results = {}\n",
    "        for attr in set(sensitive_attribute):\n",
    "            attr_texts = [t for t, a in zip(texts, sensitive_attribute) if a == attr]\n",
    "            attr_labels = [l for l, a in zip(labels, sensitive_attribute) if a == attr]\n",
    "            results[attr] = self.evaluate_texts(attr_texts, attr_labels)['accuracy']\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def evaluate_calibration(self, texts: List[str], labels: List[int], n_bins: int = 10):\n",
    "        confidences = []\n",
    "        predictions = []\n",
    "        for text in texts:\n",
    "            inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "                conf, pred = torch.max(probs, dim=1)\n",
    "                confidences.append(conf.item())\n",
    "                predictions.append(pred.item())\n",
    "        \n",
    "        accuracies = []\n",
    "        bin_confidences = []\n",
    "        for i in range(n_bins):\n",
    "            bin_mask = (i/n_bins <= np.array(confidences)) & (np.array(confidences) < (i+1)/n_bins)\n",
    "            if np.sum(bin_mask) > 0:\n",
    "                accuracies.append(accuracy_score(np.array(labels)[bin_mask], np.array(predictions)[bin_mask]))\n",
    "                bin_confidences.append(np.mean(np.array(confidences)[bin_mask]))\n",
    "        \n",
    "        return {\n",
    "            'accuracies': accuracies,\n",
    "            'confidences': bin_confidences\n",
    "        }\n",
    "\n",
    "    def plot_calibration_curve(self, calibration_results: Dict):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(calibration_results['confidences'], calibration_results['accuracies'], marker='o')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.xlabel('Confidence')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Calibration Curve')\n",
    "        plt.savefig('calibration_curve.png')\n",
    "        plt.close()\n",
    "\n",
    "    def plot_confusion_matrix(self, conf_matrix: np.ndarray):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "\n",
    "# Usage example\n",
    "evaluator = AdvancedModelEvaluation(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Classification evaluation\n",
    "classification_results = evaluator.evaluate_classification('glue', 'sst2', 'sentence', 'label')\n",
    "print(\"Classification Results:\", classification_results)\n",
    "evaluator.plot_confusion_matrix(classification_results['confusion_matrix'])\n",
    "\n",
    "# Generation evaluation\n",
    "prompts = [\"Translate to French: Hello, how are you?\", \"Summarize: The quick brown fox jumps over the lazy dog.\"]\n",
    "references = [\"Bonjour, comment allez-vous?\", \"A fox quickly jumps over a dog.\"]\n",
    "generation_results = evaluator.evaluate_generation(prompts, references)\n",
    "print(\"Generation Results:\", generation_results)\n",
    "\n",
    "# Robustness evaluation\n",
    "def typo_perturbation(text):\n",
    "    # Simple perturbation: replace a random character with 'x'\n",
    "    chars = list(text)\n",
    "    i = np.random.randint(0, len(chars))\n",
    "    chars[i] = 'x'\n",
    "    return ''.join(chars)\n",
    "\n",
    "robustness_results = evaluator.evaluate_robustness([\"This is great!\", \"This is terrible.\"], [1, 0], typo_perturbation)\n",
    "print(\"Robustness Results:\", robustness_results)\n",
    "\n",
    "# Fairness evaluation\n",
    "texts = [\"The movie was great!\", \"I didn't like the book.\", \"The restaurant was okay.\"] * 2\n",
    "labels = [1, 0, 1] * 2\n",
    "sensitive_attr = [\"male\", \"female\", \"male\", \"female\", \"male\", \"female\"]\n",
    "fairness_results = evaluator.evaluate_fairness(texts, labels, sensitive_attr)\n",
    "print(\"Fairness Results:\", fairness_results)\n",
    "\n",
    "# Calibration evaluation\n",
    "calibration_results = evaluator.evaluate_calibration(texts, labels)\n",
    "evaluator.plot_calibration_curve(calibration_results)\n",
    "print(\"Calibration Results:\", calibration_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea4dff9",
   "metadata": {},
   "source": [
    "This code demonstrates a comprehensive evaluation framework for large language models, including classification performance, generation quality, robustness to perturbations, fairness across sensitive attributes, and model calibration.\n",
    "\n",
    "### 4.8.4 Reflection\n",
    "\n",
    "Accurate performance estimation and evaluation are essential for understanding the true capabilities and limitations of large language models. These techniques help in identifying areas for improvement and potential risks associated with model deployment.\n",
    "\n",
    "Consider the following questions:\n",
    "\n",
    "1. How can we design evaluation metrics that capture the nuanced performance of LLMs across various tasks and domains?\n",
    "2. What are the challenges in evaluating the safety and ethical implications of large language models?\n",
    "3. How might we incorporate human evaluation effectively in the assessment of LLM performance, especially for subjective tasks?\n",
    "\n",
    "# 5. Summary\n",
    "\n",
    "## 5.1 Conclusion\n",
    "\n",
    "In this comprehensive lesson on LLM development fundamentals, we've explored a wide range of advanced concepts and techniques crucial for developing and deploying state-of-the-art language models. From sophisticated tokenization and prompting strategies to advanced fine-tuning techniques, reward modeling, and efficient quantization, we've covered the key aspects of the LLM development pipeline.\n",
    "\n",
    "Key takeaways include:\n",
    "\n",
    "- The importance of advanced tokenization techniques in capturing linguistic nuances\n",
    "- The power of sophisticated prompting strategies in enhancing model performance\n",
    "- The critical role of comprehensive data preparation and preprocessing\n",
    "- The nuances of pre-training and fine-tuning methodologies for optimal model performance\n",
    "- The potential of reward modeling and reinforcement learning in aligning models with human preferences\n",
    "- The necessity of efficient quantization for deploying models in resource-constrained environments\n",
    "- The crucial importance of accurate and comprehensive model evaluation\n",
    "\n",
    "As the field of LLM development continues to evolve rapidly, mastering these fundamental concepts and techniques will be essential for researchers and practitioners aiming to push the boundaries of what's possible with large language models.\n",
    "\n",
    "## 5.2 Mind Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b6eda",
   "metadata": {},
   "source": [
    "![Mermaid diagram](lesson_04_mermaid_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a521d",
   "metadata": {},
   "source": [
    "## 5.3 Preview\n",
    "\n",
    "In our next lesson, we'll delve deeper into advanced LLM architectures and scaling techniques. We'll explore how recent innovations in model design, such as mixture of experts and sparse attention mechanisms, are pushing the boundaries of what's possible with large language models. Get ready to uncover the cutting-edge developments shaping the future of AI!\n",
    "\n",
    "# 6. Homework\n",
    "\n",
    "1. Implement a custom tokenizer that can handle multiple languages and compare its performance with standard tokenizers from popular libraries.\n",
    "\n",
    "2. Design and implement an advanced prompting strategy for a complex reasoning task (e.g., multi-step mathematical problem-solving). Compare its performance with standard prompting techniques.\n",
    "\n",
    "3. Develop a data preparation pipeline that includes advanced cleaning, augmentation, and bias mitigation techniques. Apply this pipeline to a real-world dataset and analyze its impact on model performance.\n",
    "\n",
    "4. Implement a pre-training methodology that incorporates curriculum learning. Evaluate its effectiveness compared to standard pre-training approaches.\n",
    "\n",
    "5. Design and implement a parameter-efficient fine-tuning method (e.g., adapters or LoRA). Compare its performance and computational efficiency with full fine-tuning.\n",
    "\n",
    "6. Develop a reward modeling system for a specific task (e.g., text summarization) and use it to fine-tune a language model using reinforcement learning techniques.\n",
    "\n",
    "7. Implement and compare different quantization strategies for a pre-trained language model. Analyze the trade-offs between model size, inference speed, and performance.\n",
    "\n",
    "8. Design a comprehensive evaluation framework for a multi-task language model. Include metrics for performance, robustness, fairness, and safety. Apply this framework to evaluate a real model and present your findings.\n",
    "\n",
    "# 7. Reference and Citation\n",
    "\n",
    "[1] Wu, Y., et al. (2016). Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. arXiv preprint arXiv:1609.08144.\n",
    "\n",
    "[2] Brown, T., et al. (2020). Language Models are Few-Shot Learners. Advances in Neural Information Processing Systems, 33, 1877-1901.\n",
    "\n",
    "[3] Zhao, J., et al. (2017). Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints. arXiv preprint arXiv:1707.09457.\n",
    "\n",
    "[4] Devlin, J., et al. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv preprint arXiv:1810.04805.\n",
    "\n",
    "[5] Houlsby, N., et al. (2019). Parameter-Efficient Transfer Learning for NLP. arXiv preprint arXiv:1902.00751.\n",
    "\n",
    "[6] Ouyang, L., et al. (2022). Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155.\n",
    "\n",
    "[7] Jacob, B., et al. (2018). Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 2704-2713).\n",
    "\n",
    "[8] Ribeiro, M.T., et al. (2020). Beyond Accuracy: Behavioral Testing of NLP Models with CheckList. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (pp. 4902-4912).\n",
    "\n",
    "[9] Raffel, C., et al. (2019). Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. arXiv preprint arXiv:1910.10683.\n",
    "\n",
    "[10] Radford, A., et al. (2019). Language Models are Unsupervised Multitask Learners. OpenAI Blog, 1(8), 9."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
